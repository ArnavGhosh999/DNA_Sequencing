{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b084c214-ede7-423e-9058-6fcc79134d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5980e2f67d7d44bfb55fc3f8f7ea5e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìÅ Folder Upload: .fna, .fana, .fa, .fasta, .json, .jsonl files</h3>'), HTML(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "def parse_fasta_content(content):\n",
    "    sequences = {}\n",
    "    current_seq = \"\"\n",
    "    current_name = None\n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('>'):\n",
    "            if current_name and current_seq:\n",
    "                sequences[current_name] = current_seq.upper()\n",
    "            current_name = line[1:].split()[0]\n",
    "            current_seq = \"\"\n",
    "        elif line and not line.startswith(';'):\n",
    "            current_seq += line.replace(' ', '').replace('\\t', '')\n",
    "    if current_name and current_seq:\n",
    "        sequences[current_name] = current_seq.upper()\n",
    "    return sequences\n",
    "\n",
    "def parse_jsonl_content(content):\n",
    "    lines = content.strip().split('\\n')\n",
    "    items = [json.loads(line) for line in lines if line.strip()]\n",
    "    return items\n",
    "\n",
    "def upload_folder_widget():\n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.fna,.fana,.fa,.fasta,.json,.jsonl',  \n",
    "        multiple=True,\n",
    "        description='Upload Folder Files'\n",
    "    )\n",
    "    status_html = widgets.HTML(\n",
    "        \"<p><i>Upload files (.fna, .fana, .fa, .fasta, .json, .jsonl)...</i></p>\"\n",
    "    )\n",
    "    output = widgets.Output()\n",
    "    uploaded_sequences = {}\n",
    "    uploaded_json = {}\n",
    "    uploaded_jsonl = []\n",
    "    def on_upload(change):\n",
    "        output.clear_output()\n",
    "        status_html.value = \"<p><i>Processing files...</i></p>\"\n",
    "        try:\n",
    "            uploaded_json.clear()\n",
    "            uploaded_jsonl.clear()\n",
    "            uploaded_sequences.clear()\n",
    "            for filename, fileinfo in file_upload.value.items():\n",
    "                content = fileinfo.get('content', None)\n",
    "                with output:\n",
    "                    print(f\"---\\nProcessing file: {filename}\")\n",
    "                    if content is None:\n",
    "                        print(\"  ‚ùå No content field found!\")\n",
    "                        continue\n",
    "                    # Robust decoding\n",
    "                    if isinstance(content, bytes):\n",
    "                        try:\n",
    "                            content_str = content.decode('utf-8')\n",
    "                        except Exception as e:\n",
    "                            print(f\"  ‚ùå Decode error: {e}\")\n",
    "                            continue\n",
    "                    elif isinstance(content, str):\n",
    "                        content_str = content\n",
    "                    else:\n",
    "                        print(f\"  ‚ùå Unknown content type: {type(content)}\")\n",
    "                        continue\n",
    "                    ext = filename.split('.')[-1].lower()\n",
    "                    print(f\"  Extension: .{ext}\")\n",
    "                    print(f\"  First 80 chars:\\n{content_str[:80]}\")\n",
    "                    if ext in ['fa', 'fna', 'fasta', 'fana']:\n",
    "                        try:\n",
    "                            seqs = parse_fasta_content(content_str)\n",
    "                            if not seqs:\n",
    "                                print(\"  ‚ùå No sequences parsed! Check FASTA format.\")\n",
    "                            else:\n",
    "                                uploaded_sequences.update(seqs)\n",
    "                                print(f\"  üü¢ Parsed sequences from: {filename}\")\n",
    "                                for k, v in seqs.items():\n",
    "                                    print(f\"    - {k} ({len(v)} bp)\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"  ‚ùå FASTA parse error: {e}\")\n",
    "                    elif ext == 'json':\n",
    "                        try:\n",
    "                            data = json.loads(content_str)\n",
    "                            uploaded_json[filename] = data\n",
    "                            print(f\"  üü¢ Loaded JSON file: {filename}\")\n",
    "                            print(f\"    Top-level keys: {list(data.keys())}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"  ‚ùå JSON parse error: {e}\")\n",
    "                    elif ext == 'jsonl':\n",
    "                        try:\n",
    "                            items = parse_jsonl_content(content_str)\n",
    "                            uploaded_jsonl.extend(items)\n",
    "                            print(f\"  üü¢ Loaded JSONL file: {filename} ({len(items)} records)\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"  ‚ùå JSONL parse error: {e}\")\n",
    "                    else:\n",
    "                        print(f\"  ‚è≠Ô∏è Skipped unknown file type: {filename}\")\n",
    "            status_html.value = \"<p style='color:green;'>Upload finished. All files processed.</p>\"\n",
    "        except Exception as e:\n",
    "            status_html.value = f\"<p style='color:red;'>‚ùå Error: {e}</p>\"\n",
    "    file_upload.observe(on_upload, names='value')\n",
    "    vbox = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìÅ Folder Upload: .fna, .fana, .fa, .fasta, .json, .jsonl files</h3>\"),\n",
    "        status_html,\n",
    "        file_upload,\n",
    "        output\n",
    "    ])\n",
    "    display(vbox)\n",
    "    return uploaded_sequences, uploaded_json, uploaded_jsonl\n",
    "\n",
    "uploaded_sequences, uploaded_json, uploaded_jsonl = upload_folder_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca8e853-6064-45da-b073-6b7b6dcacd28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No sequences uploaded. Please upload a FASTA file first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     sequence_name, sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(uploaded_sequences\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sequences uploaded. Please upload a FASTA file first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m model_ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiomistral/biomistral-7b-bio-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m task_instruction \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredict the RNA folding kinetics and pathways for the following RNA sequence \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing the same kinetic models. List folding intermediates, key transition steps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand comment on the folding pathway if possible.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNA sequence:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msequence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No sequences uploaded. Please upload a FASTA file first."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Example: pick the first uploaded sequence\n",
    "if uploaded_sequences:\n",
    "    sequence_name, sequence = next(iter(uploaded_sequences.items()))\n",
    "else:\n",
    "    raise ValueError(\"No sequences uploaded. Please upload a FASTA file first.\")\n",
    "\n",
    "model_ckpt = \"biomistral/biomistral-7b-bio-v0.1\"\n",
    "\n",
    "task_instruction = (\n",
    "    \"Predict the RNA folding kinetics and pathways for the following RNA sequence \"\n",
    "    \"using the same kinetic models. List folding intermediates, key transition steps, \"\n",
    "    \"and comment on the folding pathway if possible.\\n\\n\"\n",
    "    f\"RNA sequence:\\n{sequence}\\n\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Using sequence: {sequence_name} ({len(sequence)} bp)\")\n",
    "print(\"Querying model for folding kinetics and pathways...\")\n",
    "\n",
    "# Load model + tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_ckpt, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Use CUDA if available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "nlp = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Generate prediction\n",
    "result = nlp(task_instruction, max_new_tokens=250)[0]['generated_text']\n",
    "\n",
    "print(\"=== Model Output ===\\n\")\n",
    "if task_instruction in result:\n",
    "    print(result[len(task_instruction):].strip())\n",
    "else:\n",
    "    print(result.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4257a4-15ea-4458-b497-dd95b9ba7bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
